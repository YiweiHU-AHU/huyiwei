{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_click_log = pd.read_csv(r\"C:\\Users\\YIwei HU\\Desktop\\天池比赛-推荐系统新闻预测\\train_click_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199999</td>\n",
       "      <td>160417</td>\n",
       "      <td>1507029570190</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199999</td>\n",
       "      <td>5408</td>\n",
       "      <td>1507029571478</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199999</td>\n",
       "      <td>50823</td>\n",
       "      <td>1507029601478</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199998</td>\n",
       "      <td>157770</td>\n",
       "      <td>1507029532200</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199998</td>\n",
       "      <td>96613</td>\n",
       "      <td>1507029671831</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112618</th>\n",
       "      <td>33446</td>\n",
       "      <td>16346</td>\n",
       "      <td>1508212054157</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112619</th>\n",
       "      <td>0</td>\n",
       "      <td>30760</td>\n",
       "      <td>1508211672520</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112620</th>\n",
       "      <td>0</td>\n",
       "      <td>157507</td>\n",
       "      <td>1508211702520</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112621</th>\n",
       "      <td>199178</td>\n",
       "      <td>234481</td>\n",
       "      <td>1508211513583</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112622</th>\n",
       "      <td>199178</td>\n",
       "      <td>233578</td>\n",
       "      <td>1508211543583</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1112623 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  click_article_id  click_timestamp  click_environment  \\\n",
       "0         199999            160417    1507029570190                  4   \n",
       "1         199999              5408    1507029571478                  4   \n",
       "2         199999             50823    1507029601478                  4   \n",
       "3         199998            157770    1507029532200                  4   \n",
       "4         199998             96613    1507029671831                  4   \n",
       "...          ...               ...              ...                ...   \n",
       "1112618    33446             16346    1508212054157                  4   \n",
       "1112619        0             30760    1508211672520                  4   \n",
       "1112620        0            157507    1508211702520                  4   \n",
       "1112621   199178            234481    1508211513583                  4   \n",
       "1112622   199178            233578    1508211543583                  4   \n",
       "\n",
       "         click_deviceGroup  click_os  click_country  click_region  \\\n",
       "0                        1        17              1            13   \n",
       "1                        1        17              1            13   \n",
       "2                        1        17              1            13   \n",
       "3                        1        17              1            25   \n",
       "4                        1        17              1            25   \n",
       "...                    ...       ...            ...           ...   \n",
       "1112618                  3         2              1            25   \n",
       "1112619                  1        17              1            25   \n",
       "1112620                  1        17              1            25   \n",
       "1112621                  3         2              1            25   \n",
       "1112622                  3         2              1            25   \n",
       "\n",
       "         click_referrer_type  \n",
       "0                          1  \n",
       "1                          1  \n",
       "2                          1  \n",
       "3                          5  \n",
       "4                          5  \n",
       "...                      ...  \n",
       "1112618                    1  \n",
       "1112619                    2  \n",
       "1112620                    2  \n",
       "1112621                    2  \n",
       "1112622                    2  \n",
       "\n",
       "[1112623 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_click_log "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testA_click_log = pd.read_csv(r\"C:\\Users\\YIwei HU\\Desktop\\天池比赛-推荐系统新闻预测\\testA_click_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testA_click_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() \n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() \n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 80108984.00 MB\n",
      "Memory usage after optimization is: 24477834.00 MB\n",
      "Decreased by 69.4%\n",
      "Memory usage of dataframe is 37296848.00 MB\n",
      "Memory usage after optimization is: 11396348.00 MB\n",
      "Decreased by 69.4%\n"
     ]
    }
   ],
   "source": [
    "train_click_log = reduce_mem_usage(train_click_log)\n",
    "testA_click_log = reduce_mem_usage(testA_click_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data = train_click_log.groupby('user_id')['click_article_id'].apply(list).reset_index()\n",
    "val_data = testA_click_log.groupby('user_id')['click_article_id'].apply(list).reset_index()\n",
    "trn_user_items = {}\n",
    "val_user_items = {}\n",
    "\n",
    "# 将数组构造成字典的形式{user_id: [item_id1, item_id2,...,item_idn]}\n",
    "for user, movies in zip(*(list(trn_data['user_id']), list(trn_data['click_article_id']))):\n",
    "    trn_user_items[user] = set(movies)\n",
    "for user, movies in zip(*(list(val_data['user_id']), list(val_data['click_article_id']))):\n",
    "    val_user_items[user] = set(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def User_CF_Rec(trn_user_items, val_user_items, K, N):\n",
    "    '''\n",
    "    trn_user_items: 表示训练数据，格式为：{user_id1: [item_id1, item_id2,...,item_idn], user_id2...}\n",
    "    val_user_items: 表示验证数据，格式为：{user_id1: [item_id1, item_id2,...,item_idn], user_id2...}\n",
    "    K: Ｋ表示的是相似用户的数量，每个用户都选择与其最相似的K个用户\n",
    "    N: N表示的是给用户推荐的商品数量，给每个用户推荐相似度最大的N个商品\n",
    "    '''\n",
    "\n",
    "    # 建立item->users倒排表\n",
    "    # 倒排表的格式为: {item_id1: {user_id1, user_id2, ... , user_idn}, item_id2: ...} 也就是每个item对应有那些用户有过点击\n",
    "    # 建立倒排表的目的就是为了更好的统计用户之间共同交互的商品数量\n",
    "    print('建立倒排表...')\n",
    "    item_users = {}\n",
    "    for uid, items in tqdm(trn_user_items.items()): # 遍历每一个用户的数据,其中包含了该用户所有交互的item\n",
    "        for item in items: # 遍历该用户的所有item, 给这些item对应的用户列表添加对应的uid\n",
    "            if item not in item_users:\n",
    "                item_users[item] = set()\n",
    "            item_users[item].add(uid)\n",
    "    \n",
    "\n",
    "    # 计算用户协同过滤矩阵\n",
    "    # 即利用item-users倒排表统计用户之间交互的商品数量，用户协同过滤矩阵的表示形式为：sim = {user_id1: {user_id2: num1}, user_id3:{user_id4: num2}, ...}\n",
    "    # 协同过滤矩阵是一个双层的字典，用来表示用户之间共同交互的商品数量\n",
    "    # 在计算用户协同过滤矩阵的同时还需要记录每个用户所交互的商品数量，其表示形式为: num = {user_id1：num1, user_id2:num2, ...}\n",
    "    sim = {}\n",
    "    num = {}\n",
    "    print('构建协同过滤矩阵...')\n",
    "    for item, users in tqdm(item_users.items()): # 遍历所有的item去统计,用户两辆之间共同交互的item数量\n",
    "        for u in users:\n",
    "            if u not in num: # 如果用户u不在字典num中，提前给其在字典中初始化为0,否则后面的运算会报key error\n",
    "                num[u] = 0\n",
    "            num[u] += 1 # 统计每一个用户,交互的总的item的数量\n",
    "            if u not in sim: # 如果用户u不在字典sim中，提前给其在字典中初始化为一个新的字典,否则后面的运算会报key error\n",
    "                sim[u] = {}\n",
    "            for v in users:\n",
    "                if u != v:  # 只有当u不等于v的时候才计算用户之间的相似度　\n",
    "                    if v not in sim[u]:\n",
    "                        sim[u][v] = 0\n",
    "                    sim[u][v] += 1\n",
    "                    \n",
    "\n",
    "    # 计算用户相似度矩阵\n",
    "    # 用户协同过滤矩阵其实相当于是余弦相似度的分子部分,还需要除以分母,即两个用户分别交互的item数量的乘积\n",
    "    # 两个用户分别交互的item数量的乘积就是上面统计的num字典\n",
    "    print('计算相似度...')\n",
    "    for u, users in tqdm(sim.items()):\n",
    "        for v, score in users.items():\n",
    "            sim[u][v] =  score / math.sqrt(num[u] * num[v]) # 余弦相似度分母部分 \n",
    "    \n",
    "\n",
    "    # 对验证数据中的每个用户进行TopN推荐\n",
    "    # 在对用户进行推荐之前需要先通过相似度矩阵得到与当前用户最相思的前K个用户，\n",
    "    # 然后对这K个用户交互的商品中除当前测试用户训练集中交互过的商品以外的商品计算最终的相似度分数\n",
    "    # 最终推荐的候选商品的相似度分数是由多个用户对该商品分数的一个累加和\n",
    "    print('给测试用户进行推荐...')\n",
    "    items_rank = {}\n",
    "    for u, _ in tqdm(val_user_items.items()): # 遍历测试集用户，给测试集中的每个用户进行推荐\n",
    "        items_rank[u] = {} # 初始化用户u的候选item的字典\n",
    "        for v, score in sorted(sim[u].items(), key=lambda x: x[1], reverse=True)[:K]: # 选择与用户u最相思的k个用户\n",
    "            for item in trn_user_items[v]: # 遍历相似用户之间交互过的商品\n",
    "                if item not in trn_user_items[u]: # 如果相似用户交互过的商品，测试用户在训练集中出现过，就不用进行推荐，直接跳过\n",
    "                    if item not in items_rank[u]:\n",
    "                        items_rank[u][item] = 0   # 初始化用户u对item的相似度分数为０\n",
    "                    items_rank[u][item] += score  # 累加所有相似用户对同一个item的分数\n",
    "    \n",
    "    print('为每个用户筛选出相似度分数最高的Ｎ个商品...')\n",
    "    items_rank = {k: sorted(v.items(), key=lambda x: x[1], reverse=True)[:N] for k, v in items_rank.items()}\n",
    "    items_rank = {k: set([x[0] for x in v]) for k, v in items_rank.items()} # 将输出整合成合适的格式输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|████████████████████████▌                                              | 69174/200000 [00:00<00:00, 686477.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "建立倒排表...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 200000/200000 [00:00<00:00, 406862.22it/s]\n",
      "  0%|                                                                                        | 0/31116 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "构建协同过滤矩阵...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▏                                                                          | 489/31116 [05:19<1:10:10,  7.27it/s]"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0e00b1cfb845>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrec_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUser_CF_Rec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrn_user_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_user_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-19e17ea24327>\u001b[0m in \u001b[0;36mUser_CF_Rec\u001b[1;34m(trn_user_items, val_user_items, K, N)\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mu\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 只有当u不等于v的时候才计算用户之间的相似度\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                         \u001b[0msim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m                     \u001b[0msim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▏                                                                          | 489/31116 [05:30<1:10:10,  7.27it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "rec_items = User_CF_Rec(trn_user_items, val_user_items, 40, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import time, math, os\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import pickle\n",
    "import random\n",
    "from datetime import datetime\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import collections\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/Users/YIwei HU/Desktop/天池比赛-推荐系统新闻预测/'\n",
    "save_path = 'tmp_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem(df):\n",
    "    starttime = time.time()\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if pd.isnull(c_min) or pd.isnull(c_max):\n",
    "                continue\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('-- Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction),time spend:{:2.2f} min'.format(end_mem,\n",
    "                                                                                                           100*(start_mem-end_mem)/start_mem,\n",
    "                                                                                                           (time.time()-starttime)/60))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_click_sample(data_path, sample_nums=10000):\n",
    "    \"\"\"\n",
    "        训练集中采样一部分数据调试\n",
    "        data_path: 原数据的存储路径\n",
    "        sample_nums: 采样数目（这里由于机器的内存限制，可以采样用户做）\n",
    "    \"\"\"\n",
    "    all_click = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "    all_user_ids = all_click.user_id.unique()\n",
    "\n",
    "    sample_user_ids = np.random.choice(all_user_ids, size=sample_nums, replace=False) \n",
    "    all_click = all_click[all_click['user_id'].isin(sample_user_ids)]\n",
    "    \n",
    "    all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))\n",
    "    return all_click\n",
    "\n",
    "# 读取点击数据，这里分成线上和线下，如果是为了获取线上提交结果应该讲测试集中的点击数据合并到总的数据中\n",
    "# 如果是为了线下验证模型的有效性或者特征的有效性，可以只使用训练集\n",
    "def get_all_click_df(data_path='C:/Users/YIwei HU/Desktop/天池比赛-推荐系统新闻预测/', offline=True):\n",
    "    if offline:\n",
    "        all_click = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "    else:\n",
    "        trn_click = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "        tst_click = pd.read_csv(data_path + 'testA_click_log.csv')\n",
    "\n",
    "        all_click = trn_click.append(tst_click)\n",
    "    \n",
    "    all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))\n",
    "    return all_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_click_df = get_all_click_df(offline=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据点击时间获取用户的点击文章序列   {user1: {item1: time1, item2: time2..}...}\n",
    "def get_user_item_time(click_df):\n",
    "    \n",
    "    click_df = click_df.sort_values('click_timestamp')\n",
    "    \n",
    "    def make_item_time_pair(df):\n",
    "        return list(zip(df['click_article_id'], df['click_timestamp']))\n",
    "    \n",
    "    user_item_time_df = click_df.groupby('user_id')['click_article_id', 'click_timestamp'].apply(lambda x: make_item_time_pair(x))\\\n",
    "                                                            .reset_index().rename(columns={0: 'item_time_list'})\n",
    "    user_item_time_dict = dict(zip(user_item_time_df['user_id'], user_item_time_df['item_time_list']))\n",
    "    \n",
    "    return user_item_time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_topk_click(click_df, k):\n",
    "    topk_click = click_df['click_article_id'].value_counts().index[:k]\n",
    "    return topk_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def itemcf_sim(df):\n",
    "    \"\"\"\n",
    "        文章与文章之间的相似性矩阵计算\n",
    "        :param df: 数据表\n",
    "        :item_created_time_dict:  文章创建时间的字典\n",
    "        return : 文章与文章的相似性矩阵\n",
    "        思路: 基于物品的协同过滤(详细请参考上一期推荐系统基础的组队学习)， 在多路召回部分会加上关联规则的召回策略\n",
    "    \"\"\"\n",
    "    \n",
    "    user_item_time_dict = get_user_item_time(df)\n",
    "    \n",
    "    # 计算物品相似度\n",
    "    i2i_sim = {}\n",
    "    item_cnt = defaultdict(int)\n",
    "    for user, item_time_list in tqdm(user_item_time_dict.items()):\n",
    "        # 在基于商品的协同过滤优化的时候可以考虑时间因素\n",
    "        for i, i_click_time in item_time_list:\n",
    "            item_cnt[i] += 1\n",
    "            i2i_sim.setdefault(i, {})\n",
    "            for j, j_click_time in item_time_list:\n",
    "                if(i == j):\n",
    "                    continue\n",
    "                i2i_sim[i].setdefault(j, 0)\n",
    "                \n",
    "                i2i_sim[i][j] += 1 / math.log(len(item_time_list) + 1)\n",
    "                \n",
    "    i2i_sim_ = i2i_sim.copy()\n",
    "    for i, related_items in i2i_sim.items():\n",
    "        for j, wij in related_items.items():\n",
    "            i2i_sim_[i][j] = wij / math.sqrt(item_cnt[i] * item_cnt[j])\n",
    "    \n",
    "    # 将得到的相似性矩阵保存到本地\n",
    "    pickle.dump(i2i_sim_, open('itemcf_i2i_sim.pkl', 'wb'))\n",
    "    \n",
    "    return i2i_sim_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 250000/250000 [00:26<00:00, 9597.83it/s]\n"
     ]
    }
   ],
   "source": [
    "i2i_sim = itemcf_sim(all_click_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "i2i_sim = pickle.load(open('itemcf_i2i_sim.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (<ipython-input-15-3bb3f3e545f8>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-15-3bb3f3e545f8>\"\u001b[1;36m, line \u001b[1;32m20\u001b[0m\n\u001b[1;33m    for j, wij in sorted(i2i_sim[i].items(), key=lambda x: x[1], reverse=True)[:sim_item_topk]:\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "def item_based_recommend(user_id, user_item_time_dict, i2i_sim, sim_item_topk, recall_item_num, item_topk_click):\n",
    "    \"\"\"\n",
    "        基于文章协同过滤的召回\n",
    "        :param user_id: 用户id\n",
    "        :param user_item_time_dict: 字典, 根据点击时间获取用户的点击文章序列   {user1: {item1: time1, item2: time2..}...}\n",
    "        :param i2i_sim: 字典，文章相似性矩阵\n",
    "        :param sim_item_topk: 整数， 选择与当前文章最相似的前k篇文章\n",
    "        :param recall_item_num: 整数v， 最后的召回文章数量\n",
    "        :param item_topk_click: 列表，点击次数最多的文章列表，用户召回补全        \n",
    "        return: 召回的文章列表 {item1:score1, item2: score2...}\n",
    "        注意: 基于物品的协同过滤(详细请参考上一期推荐系统基础的组队学习)， 在多路召回部分会加上关联规则的召回策略\n",
    "    \"\"\"\n",
    "    \n",
    "    # 获取用户历史交互的文章\n",
    "    user_hist_items = user_item_time_dict[user_id]\n",
    "    \n",
    "    item_rank = {}\n",
    "    for loc, (i, click_time) in enumerate(user_hist_items):\n",
    "        for j, wij in sorted(i2i_sim[i].items(), key=lambda x: x[1], reverse=True)[:sim_item_topk]:\n",
    "            if j in user_hist_items:\n",
    "                continue\n",
    "                \n",
    "            item_rank.setdefault(j, 0)\n",
    "            item_rank[j] +=  wij\n",
    "    \n",
    "    # 不足10个，用热门商品补全\n",
    "    if len(item_rank) < recall_item_num:\n",
    "        for i, item in enumerate(item_topk_click):\n",
    "            if item in item_rank.items(): # 填充的item应该不在原来的列表中\n",
    "                continue\n",
    "            item_rank[item] = - i - 100 # 随便给个负数就行\n",
    "            if len(item_rank) == recall_item_num:\n",
    "                break\n",
    "    \n",
    "    item_rank = sorted(item_rank.items(), key=lambda x: x[1], reverse=True)[:recall_item_num]\n",
    "        \n",
    "    return item_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义\n",
    "user_recall_items_dict = collections.defaultdict(dict)\n",
    "\n",
    "# 获取 用户 - 文章 - 点击时间的字典\n",
    "user_item_time_dict = get_user_item_time(all_click_df)\n",
    "\n",
    "# 去取文章相似度\n",
    "i2i_sim = pickle.load(open('itemcf_i2i_sim.pkl', 'rb'))\n",
    "\n",
    "# 相似文章的数量\n",
    "sim_item_topk = 10\n",
    "\n",
    "# 召回文章数量\n",
    "recall_item_num = 10\n",
    "\n",
    "# 用户热度补全\n",
    "item_topk_click = get_item_topk_click(all_click_df, k=50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(30760, 1508211672520), (157507, 1508211702520)]\n",
      "{30760, 157507}\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "    user_hist_items = user_item_time_dict[0] \n",
    "    item_rank = {} \n",
    "    print(user_hist_items) \n",
    "    for user_id, _ in user_hist_items:\n",
    "        print()\n",
    "        \n",
    "    \n",
    "    \n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 250000/250000 [00:04<00:00, 60212.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# 将字典的形式转换成df\n",
    "user_item_score_list = []\n",
    "\n",
    "for user, items in tqdm(user_recall_items_dict.items()):\n",
    "    for item, score in items:\n",
    "        user_item_score_list.append([user, item, score])\n",
    "\n",
    "recall_df = pd.DataFrame(user_item_score_list, columns=['user_id', 'click_article_id', 'pred_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199999</td>\n",
       "      <td>276970</td>\n",
       "      <td>0.172377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199999</td>\n",
       "      <td>158536</td>\n",
       "      <td>0.106969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199999</td>\n",
       "      <td>168623</td>\n",
       "      <td>0.103572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199999</td>\n",
       "      <td>123909</td>\n",
       "      <td>0.103572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199999</td>\n",
       "      <td>286321</td>\n",
       "      <td>0.097774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499995</th>\n",
       "      <td>200000</td>\n",
       "      <td>187005</td>\n",
       "      <td>0.071191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499996</th>\n",
       "      <td>200000</td>\n",
       "      <td>50573</td>\n",
       "      <td>0.071180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499997</th>\n",
       "      <td>200000</td>\n",
       "      <td>63344</td>\n",
       "      <td>0.071180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499998</th>\n",
       "      <td>200000</td>\n",
       "      <td>255153</td>\n",
       "      <td>0.068034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499999</th>\n",
       "      <td>200000</td>\n",
       "      <td>195603</td>\n",
       "      <td>0.065900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  click_article_id  pred_score\n",
       "0         199999            276970    0.172377\n",
       "1         199999            158536    0.106969\n",
       "2         199999            168623    0.103572\n",
       "3         199999            123909    0.103572\n",
       "4         199999            286321    0.097774\n",
       "...          ...               ...         ...\n",
       "2499995   200000            187005    0.071191\n",
       "2499996   200000             50573    0.071180\n",
       "2499997   200000             63344    0.071180\n",
       "2499998   200000            255153    0.068034\n",
       "2499999   200000            195603    0.065900\n",
       "\n",
       "[2500000 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成提交文件\n",
    "def submit(recall_df, topk=5, model_name=None):\n",
    "    recall_df = recall_df.sort_values(by=['user_id', 'pred_score'])\n",
    "    recall_df['rank'] = recall_df.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    \n",
    "    # 判断是不是每个用户都有5篇文章及以上\n",
    "    tmp = recall_df.groupby('user_id').apply(lambda x: x['rank'].max())\n",
    "    assert tmp.min() >= topk\n",
    "    \n",
    "    del recall_df['pred_score']\n",
    "    submit = recall_df[recall_df['rank'] <= topk].set_index(['user_id', 'rank']).unstack(-1).reset_index()\n",
    "    \n",
    "    submit.columns = [int(col) if isinstance(col, int) else col for col in submit.columns.droplevel(0)]\n",
    "    # 按照提交格式定义列名\n",
    "    submit = submit.rename(columns={'': 'user_id', 1: 'article_1', 2: 'article_2', \n",
    "                                                  3: 'article_3', 4: 'article_4', 5: 'article_5'})\n",
    "    \n",
    "    save_name =  model_name + '_' + datetime.today().strftime('%m-%d') + '.csv'\n",
    "    submit.to_csv(save_name, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取测试集\n",
    "tst_click = pd.read_csv(data_path + 'testA_click_log.csv')\n",
    "tst_users = tst_click['user_id'].unique()\n",
    "\n",
    "# 从所有的召回数据中将测试集中的用户选出来\n",
    "tst_recall = recall_df[recall_df['user_id'].isin(tst_users)]\n",
    "\n",
    "# 生成提交文件\n",
    "submit(tst_recall, topk=5, model_name='itemcf_baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_item_time_pair(df):\n",
    "    return list(zip(df['click_article_id'], df['click_timestamp']))\n",
    "a  = 8\n",
    "a.apply((lambda x: make_item_time_pair(x)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
